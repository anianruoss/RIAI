{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lucid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-78dfd0608cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlucid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlucid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelzoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision_models\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlucid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjectives\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mobjectives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lucid'"
     ]
    }
   ],
   "source": [
    "import lucid\n",
    "import lucid.modelzoo.vision_models as models\n",
    "import lucid.optvis.objectives as objectives\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import lucid.optvis.render as render\n",
    "import lucid.optvis.param as param\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm\n",
    "import cv2\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.InceptionV1()\n",
    "model.load_graphdef()\n",
    "\n",
    "# download a mapping of the imagenet class ids to text\n",
    "imagenet_classes_request = requests.get(\"https://gist.githubusercontent.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57/raw/aa66dd9dbf6b56649fa3fab83659b2acbf3cbfd1/map_clsloc.txt\")\n",
    "imagenet_classes_list = [None] + [a.split(' ')[2] for a in str(imagenet_classes_request.content).split('\\\\n')]\n",
    "\n",
    "# download an image from flickr\n",
    "response = requests.get(\"http://c1.staticflickr.com/5/4070/5148597478_0c34ec0b7e_n.jpg\")\n",
    "image = Image.open(io.BytesIO(response.content))\n",
    "image = np.array(image, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions you will want to use\n",
    "\n",
    "# compute a k-NMF of data A\n",
    "def nfm(k, A):\n",
    "    faktorizer = NMF(n_components=k)\n",
    "    shape = A.shape\n",
    "    nmf_shape = (np.prod(shape[:-1]), shape[-1])\n",
    "    U = faktorizer.fit_transform(A.reshape(nmf_shape))\n",
    "    V = faktorizer.components_\n",
    "    U = U.reshape(shape[1:-1] + (k,) )\n",
    "    V = V.reshape((k,shape[-1]) )\n",
    "    return U, V\n",
    "\n",
    "# compute the necessary forward and backward passes on a model in order to obtain\n",
    "# the activations at the desicred layer, the gradients for specific logits\n",
    "# and the evaluation of the logits\n",
    "# activations is a tensor with the actions at layer `layer`\n",
    "# grads is a list where each entry is a tensor with the gradient at layer `layer\n",
    "# from the class-logit with the same position in the array classes\n",
    "def foward_pass_and_gradients(model, image, classes, layer):\n",
    "    with tf.Graph().as_default(), tf.Session():\n",
    "        t_input = tf.placeholder_with_default(image, [None, None, 3])\n",
    "        T = render.import_model(model, t_input, t_input)\n",
    "        activations = T(layer).eval()\n",
    "        logits = T(\"softmax2_pre_activation\")\n",
    "        grads = []\n",
    "        for c in classes:\n",
    "            t_grad = tf.gradients([logits[0, c]], [T(layer)])[0]   \n",
    "            grad = t_grad.eval({T(layer) : activations})\n",
    "            grads.append(grad)\n",
    "        return activations, grads, logits.eval() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_blocks_of_interpretability(model, image, layer, classes, imagenet_classes_list, k=5,\n",
    "                                        saliency_map_treshold=0.7, visualization_size=100, diversity=1,\n",
    "                                        lambda_diversity=1e3):\n",
    "    layer_names = list(map(lambda x: x.name, model.layers))\n",
    "    assert 1 <= k\n",
    "    assert layer in layer_names\n",
    "    classes_ids = list(map(lambda x: imagenet_classes_list.index(x), classes))\n",
    "    activations, gradients, logits = foward_pass_and_gradients(model, image, classes_ids, layer)\n",
    "    top_classes = logits[0, :].ravel().argsort()[::-1][:10]\n",
    "    print('Top 10 classes:')\n",
    "    print(list(map(lambda x: imagenet_classes_list[x], top_classes.tolist())))\n",
    "    # TODO implement the aglorithm here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you are running on a CPU visualzing a 60x60 image takes roughly 1 or 2 minutes on a modern laptop. So during developement/debugging you will want to keep k and the visualization_size small or move to a GPU (for example move the notebook to colab, where you did the lucid tutorials, which allows free GPU access for 2 hour sessions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = list(map(lambda x: x.name, model.layers))\n",
    "print(layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 'mixed5a'\n",
    "target_classes = ['bloodhound', 'tiger_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a good visaualization you will need to incread the parameters a lot\n",
    "# but use this simple set for developement and debugging\n",
    "building_blocks_of_interpretability(model, image, layer, target_classes, imagenet_classes_list,\n",
    "                                    k=2, visualization_size=20, diversity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
