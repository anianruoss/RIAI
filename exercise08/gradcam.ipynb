{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "from torchvision import models, datasets, transforms\n",
    "from model import Net, ConvNet\n",
    "device = torch.device(\"cpu\")\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything that we need\n",
    "# here we load alexnet, an already trained neural network\n",
    "# you can play with other models in models.*, but for some of the others it is harder\n",
    "# to get the activations in the middle of the network\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "# define a 'layer' to norlmalize an image such that it is usable by the network\n",
    "class Normalize(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mean = torch.Tensor([0.485, 0.456, 0.406]).float().unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "        self.std = torch.Tensor([0.229, 0.224, 0.225]).float().unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        mean = self.mean.expand(x.shape)\n",
    "        std = self.std.expand(x.shape)\n",
    "        return (x - self.mean)/self.std\n",
    "\n",
    "#d efine a layer that flattens whatever it gets passed into a vector\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "# function that takes our pre-processed image and computes a numpy matrix that we can plot as an image\n",
    "def img2numpy(x):\n",
    "    x = x.clone().squeeze()\n",
    "    x = x.detach().numpy()\n",
    "    x = np.transpose(x, (1, 2, 0))\n",
    "    return x\n",
    "\n",
    "# preprocess an image for the network\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Scale(256),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# download an image from flickr\n",
    "response = requests.get(\"http://c1.staticflickr.com/5/4070/5148597478_0c34ec0b7e_n.jpg\")\n",
    "image = Image.open(io.BytesIO(response.content))\n",
    "image = preprocess(image).unsqueeze(0)\n",
    "plt.imshow(img2numpy(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download a mapping of the imagenet class ids to text\n",
    "# https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a\n",
    "imagenet_classes_request = requests.get(\"https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/c2c91c8e767d04621020c30ed31192724b863041/imagenet1000_clsid_to_human.txt\")\n",
    "print(imagenet_classes_request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the downloaded id-to-text mapping into a dict\n",
    "# before running this really inspect the output of the above comment\n",
    "# you are about to run something downloaded from the internet\n",
    "# run at your own risk\n",
    "imagenet_classes = eval(imagenet_classes_request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out the neural network\n",
    "# we want to run our normalize layer first and then alexnet\n",
    "model = nn.Sequential(Normalize(), alexnet)\n",
    "logits = model(image)\n",
    "t = alexnet(Normalize()(image)).detach().numpy().ravel().argsort()[::-1][:5]\n",
    "print('Top 5 classes for image:')\n",
    "print(list(map(lambda x: imagenet_classes[x], t.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take a closer look at the layers in the alexnet model.\n",
    "alexnet has two parts 'features' and 'classifier' where features is the conovlutional part of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that we can use the individual parts of alexnet\n",
    "# but we need to add a Flatten() layer between the two parts\n",
    "model = nn.Sequential(Normalize(), alexnet.features, Flatten(), alexnet.classifier)\n",
    "logits = model(image)\n",
    "t = alexnet(Normalize()(image)).detach().numpy().ravel().argsort()[::-1][:5]\n",
    "print('Top 5 classes for image:')\n",
    "print(list(map(lambda x: imagenet_classes[x], t.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradcam(model, image, layer, target, treshold=0.5):\n",
    "    \"\"\"\n",
    "    This method takes:\n",
    "    model - an alexnet\n",
    "    image - an input image\n",
    "    layer - an integer that indexes alexnet.features; this gives the layer that we use for the algorithm\n",
    "    target - the targetclass for visualzation\n",
    "    treshold - how much of the heatmap to show in the overlayed image\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO implement this function\n",
    "    # General appraoch:\n",
    "    # - split the model into two parts: before the targeted layer, and after\n",
    "    # - create an optimizeable variable/tensor from the output of the first part\n",
    "    # - run it through the second part (you probably need to run layer_activations.clone() instead of layer_activations due to how pytroch behaves)\n",
    "    # - call backward on the right value and optain the gradient\n",
    "    # - from there follow the algorithm from the slide/paper\n",
    "    \n",
    "    assert 1 <= layer <= 12 # layer is valid index into alexnet.features\n",
    "    L = np.ones((10, 10))\n",
    "    L_transparent = np.ones((10, 10))\n",
    "    # show the results\n",
    "    f, axarr = plt.subplots(1,3, figsize=(18, 6))\n",
    "    f.suptitle('Visualization for Class: ' + imagenet_classes[target], fontsize=16)\n",
    "    axarr[0].imshow(img2numpy(image))\n",
    "    axarr[0].set_title('Original Image')\n",
    "    axarr[1].imshow(L, interpolation='nearest')\n",
    "    axarr[1].set_title('Heatmap')\n",
    "    axarr[2].imshow(img2numpy(image))\n",
    "    axarr[2].imshow(L_transparent)\n",
    "    axarr[2].set_title('Overlay') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizeing different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 163 #'bloodhound, sleuthhound'\n",
    "gradcam(alexnet, image, 9, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 282 #tiger cat\n",
    "gradcam(alexnet, image, 9, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 243 #'bull mastiff'\n",
    "gradcam(alexnet, image, 9, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizeing one class for various different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 163 #'bloodhound, sleuthhound'\n",
    "gradcam(alexnet, image, 2, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 163 #'bloodhound, sleuthhound'\n",
    "gradcam(alexnet, image, 3, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 163 #'bloodhound, sleuthhound'\n",
    "gradcam(alexnet, image, 4, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 163 #'bloodhound, sleuthhound'\n",
    "gradcam(alexnet, image, 5, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 163 #'bloodhound, sleuthhound'\n",
    "gradcam(alexnet, image, 6, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 163 #'bloodhound, sleuthhound'\n",
    "gradcam(alexnet, image, 7, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 163 #'bloodhound, sleuthhound'\n",
    "gradcam(alexnet, image, 8, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 163 #'bloodhound, sleuthhound'\n",
    "gradcam(alexnet, image, 9, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 163 #'bloodhound, sleuthhound'\n",
    "gradcam(alexnet, image, 10, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 163 #'bloodhound, sleuthhound'\n",
    "gradcam(alexnet, image, 11, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 163 #'bloodhound, sleuthhound'\n",
    "gradcam(alexnet, image, 12, s, treshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riai",
   "language": "python",
   "name": "riai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
